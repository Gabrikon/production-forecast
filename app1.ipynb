{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9f28e-e63c-4f5e-9d01-ce833ef07b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data, models, and scalers loaded successfully.\n",
      "Features used for training: ['GROSS (bbls/d)', 'BS.W%', 'day_of_week', 'day_of_month', 'month', 'year', 'net_rolling_avg7', 'net_rolling_avg30', 'net_rolling_avg90', 'net_rolling_std7', 'net_rolling_std30', 'net_rolling_std90', 'gross_rolling_avg7', 'gross_rolling_avg30', 'gross_rolling_avg90', 'gross_rolling_std7', 'gross_rolling_std30', 'gross_rolling_std90', 'water_rolling_avg7', 'water_rolling_avg30', 'water_rolling_avg90', 'water_rolling_std7', 'water_rolling_std30', 'water_rolling_std90', 'bsw_rolling_avg7', 'bsw_rolling_avg30', 'bsw_rolling_avg90', 'bsw_rolling_std7', 'bsw_rolling_std30', 'bsw_rolling_std90', 'GROSS (bbls/d)_lag1', 'GROSS (bbls/d)_lag3', 'GROSS (bbls/d)_lag7', 'BS.W%_lag1', 'BS.W%_lag3', 'BS.W%_lag7', 'NET (bbls/d)_lag1', 'NET (bbls/d)_lag3', 'NET (bbls/d)_lag7', 'WATER (bbls/d)_lag1', 'WATER (bbls/d)_lag3', 'WATER (bbls/d)_lag7']\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.159.107:5001\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/May/2025 10:29:31] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/May/2025 10:29:31] \"POST /forecast HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received forecast request.\n",
      "Raw forecast_periods value: 30\n",
      "Requested forecast days: 30\n",
      "Last historical date: 2025-03-19 00:00:00\n",
      "Creating future features...\n",
      "Future features created.\n",
      "Scaling future features...\n",
      "Future features scaled.\n",
      "Making predictions and inverse transforming...\n",
      "Predicting for target: NET (bbls/d)\n",
      "Prediction for NET (bbls/d) complete.\n",
      "Predicting for target: WATER (bbls/d)\n",
      "Prediction for WATER (bbls/d) complete.\n",
      "Preparing data for Chart.js...\n",
      "DatetimeIndex(['2023-05-31', '2023-06-01', '2023-06-02', '2023-06-03',\n",
      "               '2023-06-04', '2023-06-05', '2023-06-06', '2023-06-07',\n",
      "               '2023-06-08', '2023-06-09',\n",
      "               ...\n",
      "               '2025-04-09', '2025-04-10', '2025-04-11', '2025-04-12',\n",
      "               '2025-04-13', '2025-04-14', '2025-04-15', '2025-04-16',\n",
      "               '2025-04-17', '2025-04-18'],\n",
      "              dtype='datetime64[ns]', length=688, freq=None)\n",
      "Data prepared for Chart.js.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/May/2025 10:30:29] \"POST /forecast HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received forecast request.\n",
      "Raw forecast_periods value: 90\n",
      "Requested forecast days: 90\n",
      "Last historical date: 2025-03-19 00:00:00\n",
      "Creating future features...\n",
      "Future features created.\n",
      "Scaling future features...\n",
      "Future features scaled.\n",
      "Making predictions and inverse transforming...\n",
      "Predicting for target: NET (bbls/d)\n",
      "Prediction for NET (bbls/d) complete.\n",
      "Predicting for target: WATER (bbls/d)\n",
      "Prediction for WATER (bbls/d) complete.\n",
      "Preparing data for Chart.js...\n",
      "DatetimeIndex(['2023-05-31', '2023-06-01', '2023-06-02', '2023-06-03',\n",
      "               '2023-06-04', '2023-06-05', '2023-06-06', '2023-06-07',\n",
      "               '2023-06-08', '2023-06-09',\n",
      "               ...\n",
      "               '2025-06-08', '2025-06-09', '2025-06-10', '2025-06-11',\n",
      "               '2025-06-12', '2025-06-13', '2025-06-14', '2025-06-15',\n",
      "               '2025-06-16', '2025-06-17'],\n",
      "              dtype='datetime64[ns]', length=748, freq=None)\n",
      "Data prepared for Chart.js.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/May/2025 10:46:36] \"POST /forecast HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received forecast request.\n",
      "Raw forecast_periods value: 180\n",
      "Requested forecast days: 180\n",
      "Last historical date: 2025-03-19 00:00:00\n",
      "Creating future features...\n",
      "Future features created.\n",
      "Scaling future features...\n",
      "Future features scaled.\n",
      "Making predictions and inverse transforming...\n",
      "Predicting for target: NET (bbls/d)\n",
      "Prediction for NET (bbls/d) complete.\n",
      "Predicting for target: WATER (bbls/d)\n",
      "Prediction for WATER (bbls/d) complete.\n",
      "Preparing data for Chart.js...\n",
      "DatetimeIndex(['2023-05-31', '2023-06-01', '2023-06-02', '2023-06-03',\n",
      "               '2023-06-04', '2023-06-05', '2023-06-06', '2023-06-07',\n",
      "               '2023-06-08', '2023-06-09',\n",
      "               ...\n",
      "               '2025-09-06', '2025-09-07', '2025-09-08', '2025-09-09',\n",
      "               '2025-09-10', '2025-09-11', '2025-09-12', '2025-09-13',\n",
      "               '2025-09-14', '2025-09-15'],\n",
      "              dtype='datetime64[ns]', length=838, freq=None)\n",
      "Data prepared for Chart.js.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import joblib\n",
    "import traceback\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# --- File Paths ---\n",
    "DATA_PATH = 'filled_oil.csv'\n",
    "MODELS_PATH = 'final_models.joblib'\n",
    "FEATURE_SCALER_PATH = 'feature_scaler.joblib'\n",
    "TARGET_SCALERS_PATH = 'target_scalers.joblib'\n",
    "\n",
    "# --- Load Data, Models, and Scalers ---\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH, parse_dates=['DATE'])\n",
    "    df = df.set_index('DATE').sort_index()\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "    df[df.select_dtypes(include=[np.number]).columns] = df.select_dtypes(include=[np.number]).clip(lower=0)\n",
    "\n",
    "    # Load the trained models and scalers\n",
    "    final_models = joblib.load(MODELS_PATH)\n",
    "    feature_scaler = joblib.load(FEATURE_SCALER_PATH)\n",
    "    target_scalers = joblib.load(TARGET_SCALERS_PATH)\n",
    "\n",
    "    print(\"Data, models, and scalers loaded successfully.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading required files: {e}\")\n",
    "    print(\"Please ensure 'filled_oil.csv', 'final_models.joblib', 'feature_scaler.joblib', and 'target_scalers.joblib' are in the same directory as app.py\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during loading: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Feature Engineering Functions ---\n",
    "def create_features(df):\n",
    "    \"\"\"Creates time-based and rolling window features.\"\"\"\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['day_of_month'] = df.index.day\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    col_mapping = {\n",
    "        'NET (bbls/d)': 'net',\n",
    "        'GROSS (bbls/d)': 'gross',\n",
    "        'WATER (bbls/d)': 'water',\n",
    "        'BS.W%': 'bsw'\n",
    "    }\n",
    "    # Create rolling windows for key columns\n",
    "    for orig_col, col_std in col_mapping.items():\n",
    "        # Use .copy() to avoid SettingWithCopyWarning\n",
    "        #col_std = col.split(\" \")[0].lower()\n",
    "        df[f'{col_std}_rolling_avg7'] = df[orig_col].rolling(7).mean().copy()\n",
    "        df[f'{col_std}_rolling_avg30'] = df[orig_col].rolling(30).mean().copy()\n",
    "        df[f'{col_std}_rolling_avg90'] = df[orig_col].rolling(90).mean().copy()\n",
    "        df[f'{col_std}_rolling_std7'] = df[orig_col].rolling(7).std().copy()\n",
    "        df[f'{col_std}_rolling_std30'] = df[orig_col].rolling(30).std().copy()\n",
    "        df[f'{col_std}_rolling_std90'] = df[orig_col].rolling(90).std().copy()\n",
    "\n",
    "    # Create lag features\n",
    "    for col in ['GROSS (bbls/d)', 'BS.W%', 'NET (bbls/d)', 'WATER (bbls/d)']:\n",
    "        for lag in [1, 3, 7]:\n",
    "            # Use .copy() to avoid SettingWithCopyWarning\n",
    "            df[f'{col}_lag{lag}'] = df[col].shift(lag).copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to get the expected feature names\n",
    "df_features_engineered = create_features(df.copy())\n",
    "df_features_engineered = df_features_engineered.dropna()  # Drop NaNs\n",
    "\n",
    "# Define features and targets based on the processed historical data\n",
    "targets = ['NET (bbls/d)', 'WATER (bbls/d)']\n",
    "features = [col for col in df_features_engineered.columns if col not in targets]\n",
    "print(f\"Features used for training: {features}\")\n",
    "\n",
    "def create_future_features_with_bootstrap(last_date, periods, historical_df, features, n_samples=100):\n",
    "    \"\"\"\n",
    "    Creates future features using bootstrapping from recent historical data.\n",
    "    \"\"\"\n",
    "    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=periods)\n",
    "    future_df = pd.DataFrame(index=future_dates)\n",
    "\n",
    "    # Basic time features\n",
    "    future_df['day_of_week'] = future_df.index.dayofweek\n",
    "    future_df['day_of_month'] = future_df.index.day\n",
    "    future_df['month'] = future_df.index.month\n",
    "    future_df['year'] = future_df.index.year\n",
    "\n",
    "    # Mapping between original columns and their standardized names\n",
    "    col_mapping = {\n",
    "        'NET (bbls/d)': 'net',\n",
    "        'GROSS (bbls/d)': 'gross',\n",
    "        'WATER (bbls/d)': 'water',\n",
    "        'BS.W%': 'bsw'\n",
    "    }\n",
    "\n",
    "    # Create bootstrap samples for each target column\n",
    "    for orig_col, std_col in col_mapping.items():\n",
    "        # Get recent data (last 90 days for better bootstrap)\n",
    "        recent_data = historical_df[orig_col].values[-90:]\n",
    "\n",
    "        # Generate bootstrap samples\n",
    "        bootstrap_samples = np.random.choice(recent_data, size=(periods, n_samples), replace=True)\n",
    "\n",
    "        # Calculate statistics from bootstrap samples\n",
    "        future_df[f'{std_col}_mean'] = bootstrap_samples.mean(axis=1)\n",
    "        future_df[f'{std_col}_std'] = bootstrap_samples.std(axis=1)\n",
    "        future_df[f'{std_col}_median'] = np.median(bootstrap_samples, axis=1)\n",
    "\n",
    "        # Store both versions - original and standardized\n",
    "        future_df[orig_col] = future_df[f'{std_col}_median']  # Original name for lag features\n",
    "        future_df[std_col] = future_df[f'{std_col}_median']   # Standardized name for rolling features\n",
    "\n",
    "    # Create rolling features using standardized names\n",
    "    window_sizes = [7, 30, 90]\n",
    "    for std_col in col_mapping.values():\n",
    "        for window in window_sizes:\n",
    "            # Rolling averages\n",
    "            future_df[f'{std_col}_rolling_avg{window}'] = future_df[std_col].rolling(window).mean()\n",
    "            # Rolling std\n",
    "            future_df[f'{std_col}_rolling_std{window}'] = future_df[std_col].rolling(window).std()\n",
    "\n",
    "        # Forward fill the initial NaN values using ffill()\n",
    "        for window in window_sizes:\n",
    "            future_df[f'{std_col}_rolling_avg{window}'] = future_df[f'{std_col}_rolling_avg{window}'].ffill()\n",
    "            future_df[f'{std_col}_rolling_std{window}'] = future_df[f'{std_col}_rolling_std{window}'].ffill()\n",
    "\n",
    "    # Create lag features using original column names\n",
    "    for orig_col in col_mapping.keys():\n",
    "        for lag in [1, 3, 7]:\n",
    "            future_df[f'{orig_col}_lag{lag}'] = future_df[orig_col].shift(lag)\n",
    "            # Fill initial NaN values with the first available value using ffill()\n",
    "            future_df[f'{orig_col}_lag{lag}'] = future_df[f'{orig_col}_lag{lag}'].ffill()\n",
    "\n",
    "    # Ensure all required feature columns are present\n",
    "    for feature in features:\n",
    "        if feature not in future_df.columns:\n",
    "            print(f\"Adding missing feature: {feature}\")\n",
    "            future_df[feature] = np.nan  # Add missing columns as NaN\n",
    "\n",
    "    # Forward fill any remaining NaN values\n",
    "    future_df = future_df.ffill().bfill()  # Use bfill() as well in case ffill() doesn't cover everything\n",
    "\n",
    "    return future_df\n",
    "\n",
    "# --- Flask Routes ---\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Renders the main page with input for forecast days.\"\"\"\n",
    "    return render_template('updated_index_html.html')\n",
    "\n",
    "@app.route('/forecast', methods=['POST'])\n",
    "def forecast():\n",
    "    \"\"\"Generates and returns the forecast data for both targets as JSON for Chart.js.\"\"\"\n",
    "    try:\n",
    "        print(\"Received forecast request.\")\n",
    "        \n",
    "        # Get forecast_periods from form data\n",
    "        forecast_periods = request.form.get('forecast_periods')\n",
    "        print(f\"Raw forecast_periods value: {forecast_periods}\")\n",
    "        \n",
    "        if not forecast_periods:\n",
    "            print(\"Error: forecast_periods parameter is missing.\")\n",
    "            return jsonify({\"error\": \"Missing forecast periods parameter.\"}), 400\n",
    "            \n",
    "        # Convert to integer\n",
    "        days = int(forecast_periods)\n",
    "        print(f\"Requested forecast days: {days}\")\n",
    "\n",
    "        if days <= 0:\n",
    "            print(\"Error: Number of forecast days must be positive.\")\n",
    "            return jsonify({\"error\": \"Number of forecast days must be positive.\"}), 400\n",
    "\n",
    "        # Get the last date from the historical data\n",
    "        last_date = df.index[-1]\n",
    "        print(f\"Last historical date: {last_date}\")\n",
    "\n",
    "        print(\"Creating future features...\")\n",
    "        # Generate future features using bootstrapping\n",
    "        future_df = create_future_features_with_bootstrap(last_date, days, df, features)\n",
    "        print(\"Future features created.\")\n",
    "        \n",
    "        # Debug output - check if all required features are present\n",
    "        missing_cols = set(features) - set(future_df.columns)\n",
    "        if missing_cols:\n",
    "            print(f\"WARNING: Missing columns after feature creation: {missing_cols}\")\n",
    "            # Add missing columns with zero values\n",
    "            for col in missing_cols:\n",
    "                future_df[col] = 0\n",
    "\n",
    "        print(\"Scaling future features...\")\n",
    "        # Make sure all columns are in the same order as features list\n",
    "        future_df_ordered = future_df[features]\n",
    "        # Scale future features\n",
    "        future_df_scaled = feature_scaler.transform(future_df_ordered)\n",
    "        future_df_scaled = pd.DataFrame(future_df_scaled, columns=features, index=future_df.index)\n",
    "        print(\"Future features scaled.\")\n",
    "\n",
    "        print(\"Making predictions and inverse transforming...\")\n",
    "        # Make predictions and inverse transform for both targets\n",
    "        forecasts = {}\n",
    "        for target in targets:\n",
    "            print(f\"Predicting for target: {target}\")\n",
    "            preds_scaled = final_models[target].predict(future_df_scaled)\n",
    "            preds_original = target_scalers[target].inverse_transform(\n",
    "                preds_scaled.reshape(-1, 1)).flatten()\n",
    "            forecasts[target] = pd.Series(preds_original, index=future_df.index)\n",
    "            print(f\"Prediction for {target} complete.\")\n",
    "\n",
    "        print(\"Preparing data for Chart.js...\")\n",
    "        # Prepare data for Chart.js - include historical data for context\n",
    "        combined_net = pd.concat([df['NET (bbls/d)'], forecasts['NET (bbls/d)']])\n",
    "        combined_water = pd.concat([df['WATER (bbls/d)'], forecasts['WATER (bbls/d)']])\n",
    "        \n",
    "        # Sort by date and remove duplicates (keep the first occurrence)\n",
    "        combined_net = combined_net.sort_index().groupby(level=0).first()\n",
    "        combined_water = combined_water.sort_index().groupby(level=0).first()\n",
    "        print(combined_net.index)\n",
    "        # Format for Chart.js\n",
    "        chart_data = {\n",
    "            'labels': combined_net.index.strftime('%Y-%m-%d').tolist(),\n",
    "            'net_production': combined_net.values.tolist(),\n",
    "            'water_production': combined_water.values.tolist()\n",
    "        }\n",
    "        print(\"Data prepared for Chart.js.\")\n",
    "\n",
    "        # Return the data as JSON\n",
    "        return jsonify(chart_data)\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        return jsonify({\"error\": \"Invalid number of forecast days. Please enter a whole number.\"}), 400\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during forecasting: {e}\")\n",
    "        traceback.print_exc()  # Print detailed traceback\n",
    "        return jsonify({\"error\": f\"An error occurred during forecasting: {str(e)}\"}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(\n",
    "            host='0.0.0.0',  # Explicitly set host\n",
    "            port=5001,       # Use alternative port\n",
    "            debug=True,      # Debug mode\n",
    "            use_reloader=False,  # Disable reloader\n",
    "            use_debugger=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting Flask app: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee2cc9e-f611-4b36-8ff2-a86d9cfb5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4e8b0-2720-443d-ac8c-a1365f6e58ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
